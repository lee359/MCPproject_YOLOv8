# YOLOv8 + MCP + Claude 整合系統實驗方法設計# 三、實驗方法

**版本：v1.1**  

**日期：2025-11-06**  ## 3.1 實驗設計

**專題主題：透過 MCP 工具調用 YOLOv8 進行 ESP32-CAM 即時影像辨識**

本研究旨在評估基於 Model Context Protocol (MCP) 的即時影像辨識系統效能。系統架構為：Claude 透過 MCP 工具調用 YOLOv8 模型，直接從 ESP32-CAM 串流擷取影像並進行物體辨識，有別於傳統需要手動上傳圖片或影片給 Claude 的方式。實驗採用控制變數法，固定 ESP32-CAM 的位置與光照條件（正常室內光照），專注於測試 MCP 工具的即時處理效能、不同工具的執行效率，以及 Kalman Filter 追蹤演算法對辨識穩定性的影響。

**更新說明**：基於精簡化的 MCP 工具返回指標，調整數據記錄方法與評估指標

實驗分為三個主要部分：**場景複雜度測試**、**MCP 工具即時處理能力測試**，以及 **Kalman Filter 追蹤效能評估**。每個實驗條件重複 10 次，以確保數據的可靠性與重複性。

---

---

## 📋 目錄

1. [實驗目標](#實驗目標)## 3.2 實驗架構

2. [實驗設計原則](#實驗設計原則)

3. [實驗架構](#實驗架構)### 3.2.1 場景複雜度測試（實驗一）

4. [核心評估指標](#核心評估指標)本實驗設計三種不同複雜度的場景，測試 MCP 工具調用 YOLOv8 模型在不同情境下的即時辨識能力：

5. [數據記錄方法](#數據記錄方法)- **場景 A（單一物體）**：單隻貓或單隻狗，各進行 10 次即時偵測

6. [實驗流程](#實驗流程)- **場景 B（雙物體）**：貓與狗同時出現，進行 10 次即時偵測

7. [預期成果](#預期成果)- **場景 C（複雜場景）**：多隻動物加上背景物體，進行 10 次即時偵測



---每次偵測由 Claude 透過 MCP 工具 `detect_esp32_stream` 直接從 ESP32-CAM 串流（http://192.168.0.104:81/stream）擷取即時影像，無需手動上傳圖片。



## 🎯 實驗目標### 3.2.2 MCP 工具即時處理能力測試（實驗二）

比較三種 MCP 工具在即時影像辨識上的處理效能：

### 核心研究問題- **detect_esp32_stream**：完整版工具，支援多幀處理與 Kalman Filter 追蹤，返回標註後的 base64 圖像

本研究旨在評估基於 Model Context Protocol (MCP) 的即時影像辨識系統效能。系統架構為：**Claude 透過 MCP 工具調用 YOLOv8 模型，直接從 ESP32-CAM 串流擷取影像並進行物體辨識**，有別於傳統需要手動上傳圖片或影片的方式。- **detect_stream_frame_simple**：簡化版工具，單幀處理且不返回圖像，專注於快速辨識

- **detect_image**：靜態圖片偵測工具（作為對照組）

具體探討：

1. **MCP 工具即時處理效能**：`detect_esp32_stream` 和 `detect_stream_frame_simple` 在不同場景下的表現每種工具在場景 A、B、C 各進行 10 次測試，測量其端到端處理時間、YOLOv8 推論時間、影格讀取時間等效能指標。

2. **YOLOv8 辨識準確度**：在即時串流環境下的物體偵測能力

3. **Kalman Filter 追蹤效果**：對物體追蹤穩定性的影響### 3.2.3 Kalman Filter 追蹤效能評估（實驗三）

4. **系統即時性評估**：端到端處理時間是否滿足即時監控需求針對 `detect_esp32_stream` 工具，比較啟用與停用 Kalman Filter 追蹤演算法的差異：

- **啟用 Kalman Filter**（`use_kalman=True`）：使用多幀追蹤，平滑物體移動軌跡

### 研究範疇界定- **停用 Kalman Filter**（`use_kalman=False`）：僅使用當前幀的原始偵測結果

- ✅ **聚焦於**：MCP 架構即時辨識能力、ESP32-CAM 串流處理、YOLOv8 推論效能

- ❌ **不涉及**：YOLOv8 在不同光照/天氣條件下的辨識率（純 CV 研究範疇）在場景 A 和 B 各進行 10 次測試，比較邊界框穩定性、物體追蹤連續性，以及計算時間開銷。

- 🔧 **實驗環境**：固定 ESP32-CAM 位置，正常室內光照條件

---

---

## 3.3 數據記錄與分析

## 🔬 實驗設計原則

### 3.3.1 數據記錄方法

### 1. 變數控制每次實驗透過 MCP 工具自動記錄以下資訊（儲存於工具返回的 JSON 結構中）：

- **自變數**：場景複雜度、MCP 工具類型、Kalman Filter 啟用與否- **YOLOv8 偵測結果**：偵測物體類別、信心分數（confidence）、邊界框座標（bbox）

- **依變數**：辨識成功率、偵測數量、處理時間、YOLO 推論時間- **效能指標**：

- **控制變數**：光照條件、相機位置、網路環境、模型參數（imgsz=640, conf=0.25）  - `total_time`：端到端總處理時間

  - `yolo_inference_time`：YOLOv8 模型推論時間

### 2. 重複性原則  - `frame_read_time`：從 ESP32-CAM 讀取影格時間

- 每個實驗條件重複 **10 次**  - `kalman_predict_time`：Kalman Filter 計算時間（若啟用）

- 總實驗次數：3 場景 × 2 工具 × 10 次 = **60 組數據**（基礎實驗）  - `base64_encode_time`：圖像編碼時間（detect_esp32_stream）

- **串流資訊**：`stream_url`、`frame_size`（影像解析度）

### 3. 客觀性原則- **追蹤資訊**：`tracked_objects_count`、物體年齡（age）

- 使用 MCP 工具自動記錄結構化數據（JSON 格式）- **人工驗證**：實驗者標註的真實結果（Ground Truth）

- 引入人工驗證（Ground Truth）比對偵測結果

- 自動計算準確率與效能指標所有數據儲存為結構化格式，並匯出為 CSV 檔案進行統計分析。



---### 3.3.2 評估指標

本研究採用以下指標評估 MCP 即時辨識系統的表現：

## 🏗️ 實驗架構1. **偵測準確率**：正確偵測次數除以總次數（與 Ground Truth 比對）

2. **平均信心分數**：所有偵測結果的平均 confidence 值

### 實驗組別設計3. **即時性**：端到端處理時間（`total_time`），評估是否達到即時辨識需求

4. **追蹤穩定性**：啟用 Kalman Filter 時，邊界框座標的變異係數

#### **實驗一：場景複雜度測試**5. **工具效能比較**：三種 MCP 工具的平均處理時間差異

測試 MCP 工具調用 YOLOv8 在不同場景下的即時辨識能力

---

| 場景類型 | 描述 | 測試次數 | 測試工具 |

|---------|------|---------|---------|## 3.4 實驗環境

| **場景 A：單一物體** | 單隻貓或單隻狗 | 各 10 次 | detect_esp32_stream |

| **場景 B：雙物體** | 貓和狗同時出現 | 10 次 | detect_esp32_stream |### 3.4.1 硬體設備

| **場景 C：複雜場景** | 多隻動物 + 背景物體 | 10 次 | detect_esp32_stream |- **影像擷取**：ESP32-CAM 模組（固定於三腳架，提供即時串流 URL：http://192.168.0.104:81/stream）

- **運算平台**：配備 NVIDIA GPU 的個人電腦（執行 YOLOv8 推論與 MCP 伺服器）

**測試目標**：- **網路環境**：區域網路，延遲低於 50ms

- 評估不同場景複雜度對 YOLOv8 偵測準確度的影響

- 記錄各場景下的平均處理時間與 YOLO 推論時間### 3.4.2 軟體環境與系統架構

- **物體辨識模型**：YOLOv8（使用訓練好的模型 best.pt）

---- **MCP 伺服器**：FastMCP 框架（mcpclient.py）

  - 工具 1：`detect_esp32_stream`（完整版，含 Kalman Filter）

#### **實驗二：MCP 工具效能比較**  - 工具 2：`detect_stream_frame_simple`（簡化版）

比較兩種 MCP 工具在相同場景下的處理效能差異  - 工具 3：`detect_image`（靜態圖片）

  - 工具 4：`check_stream_health`（串流健康檢查）

| 工具名稱 | 特點 | 測試場景 | 測試次數 |- **MCP 客戶端**：Claude Desktop 應用程式

|---------|------|---------|---------|- **追蹤演算法**：Kalman Filter（FilterPy 函式庫）

| `detect_esp32_stream` | 完整版，含 Kalman Filter 追蹤 | 場景 A, B, C | 各 10 次 |- **影像處理**：OpenCV、NumPy

| `detect_stream_frame_simple` | 簡化版，單幀處理，不返回圖像 | 場景 A, B, C | 各 10 次 |- **GPU 加速**：PyTorch CUDA（若可用）



**測試目標**：**系統運作流程**：使用者透過 Claude Desktop 發出指令 → Claude 調用 MCP 工具（如 `detect_esp32_stream`）→ MCP 伺服器從 ESP32-CAM 擷取即時影像 → YOLOv8 進行物體辨識 → 返回偵測結果給 Claude → Claude 整理並呈現結果給使用者。

- 比較兩種工具的平均 `total_time` 差異

- 驗證簡化版工具是否能有效減少處理時間實驗前進行 3 次校準測試（使用 `check_stream_health` 工具），確認 ESP32-CAM 串流穩定後才開始正式實驗。每階段實驗結束後立即備份數據，以防資料遺失。

- 評估兩種工具的 `detection_count` 一致性

---

---

**本章節約 650 字，符合 Word A4 格式約 2/3 頁的篇幅要求**

#### **實驗三：Kalman Filter 追蹤效能評估**
針對 `detect_esp32_stream` 工具，比較啟用與停用 Kalman Filter 的差異

| 配置 | 參數設定 | 測試場景 | 測試次數 |
|------|---------|---------|---------|
| **啟用 Kalman Filter** | `use_kalman=True` | 場景 A, B | 各 10 次 |
| **停用 Kalman Filter** | `use_kalman=False` | 場景 A, B | 各 10 次 |

**測試目標**：
- 評估 Kalman Filter 對追蹤穩定性的影響
- 測量啟用 Kalman Filter 的時間開銷（通過 `total_time` 差異計算）

---

## 📊 核心評估指標

基於 MCP 工具返回的精簡化數據結構，本研究採用以下 **5 個核心指標**：

### MCP 工具返回結構
```python
{
    "timestamp": "2025-11-06T15:30:45.123456",
    "success": True,
    "detection_count": 2,
    "detections": [
        {
            "class": "cat",
            "confidence": 0.85,
            "bbox": [100, 150, 300, 400]
        }
    ],
    "total_time": 1.234,
    "yolo_inference_time": 0.456
}
```

### 5 個核心指標說明

| 指標名稱 | 類型 | 說明 | 用途 |
|---------|------|------|------|
| **`success`** | 布林值 | MCP 工具調用是否成功 | 評估系統穩定性 |
| **`detection_count`** | 整數 | 偵測到的物體數量 | 評估辨識能力 |
| **`detections`** | 陣列 | 詳細偵測結果（類別、信心分數、邊界框） | 計算準確率、平均信心分數 |
| **`total_time`** | 浮點數（秒） | 端到端總處理時間 | 評估即時性能 |
| **`yolo_inference_time`** | 浮點數（秒） | YOLOv8 模型推論時間 | 評估核心辨識速度 |

### 衍生指標計算

```python
# 1. 系統成功率
success_rate = (成功次數 / 總測試次數) × 100%

# 2. 平均信心分數
avg_confidence = mean([d["confidence"] for d in detections])

# 3. 辨識準確率（需 Ground Truth）
accuracy = (正確辨識次數 / 總測試次數) × 100%

# 4. MCP 傳輸開銷
mcp_overhead = total_time - yolo_inference_time

# 5. 每秒處理幀數（FPS）
fps = 1 / total_time
```

---

## 💾 數據記錄方法

### 自動化記錄系統（v1.1 精簡版）

```python
import pandas as pd
import numpy as np
from datetime import datetime

class MCPExperimentLogger_v1_1:
    """
    MCP 實驗數據記錄器 v1.1
    基於精簡化的 MCP 工具返回指標
    """
    
    def __init__(self, experiment_name="MCP_YOLOv8_ESP32CAM_Experiment"):
        self.experiment_name = experiment_name
        self.data = []
        self.start_time = datetime.now()
    
    def log_trial(self, scene_type, mcp_tool_name, trial_num, 
                  mcp_result, ground_truth=None, use_kalman=None):
        """
        記錄單次實驗數據
        
        Args:
            scene_type: 場景類型 ("single_cat", "single_dog", "cat_dog", "complex")
            mcp_tool_name: MCP 工具名稱 ("detect_esp32_stream", "detect_stream_frame_simple")
            trial_num: 實驗次數編號
            mcp_result: MCP 工具返回的結果（dict）
            ground_truth: 人工標註的真實結果（dict）
            use_kalman: 是否啟用 Kalman Filter（僅 detect_esp32_stream 有效）
        """
        
        # 提取偵測結果
        detections = mcp_result.get("detections", [])
        
        # 計算平均信心分數
        confidences = [d["confidence"] for d in detections]
        avg_confidence = np.mean(confidences) if confidences else 0.0
        max_confidence = np.max(confidences) if confidences else 0.0
        min_confidence = np.min(confidences) if confidences else 0.0
        
        # 提取偵測類別
        detected_classes = [d["class"] for d in detections]
        
        # 計算 MCP 傳輸開銷
        total_time = mcp_result.get("total_time", 0)
        yolo_time = mcp_result.get("yolo_inference_time", 0)
        mcp_overhead = total_time - yolo_time
        
        # 計算 FPS
        fps = 1 / total_time if total_time > 0 else 0
        
        record = {
            # ===== 基本資訊 =====
            "timestamp": mcp_result.get("timestamp", datetime.now().isoformat()),
            "experiment_name": self.experiment_name,
            "scene_type": scene_type,
            "mcp_tool": mcp_tool_name,
            "trial_number": trial_num,
            "use_kalman": use_kalman,
            
            # ===== 核心指標（直接從 MCP 結果） =====
            "success": mcp_result.get("success", False),
            "detection_count": mcp_result.get("detection_count", 0),
            "total_time": total_time,
            "yolo_inference_time": yolo_time,
            
            # ===== 偵測結果詳細資訊 =====
            "detected_classes": detected_classes,
            "confidences": confidences,
            "avg_confidence": round(avg_confidence, 4),
            "max_confidence": round(max_confidence, 4),
            "min_confidence": round(min_confidence, 4),
            "detections_json": str(detections),  # 保存完整偵測結果
            
            # ===== 衍生效能指標 =====
            "mcp_overhead": round(mcp_overhead, 4),
            "fps": round(fps, 2),
            "yolo_percentage": round((yolo_time / total_time * 100), 2) if total_time > 0 else 0,
            
            # ===== 人工驗證 =====
            "ground_truth": ground_truth,
            "is_correct": None  # 事後人工標註
        }
        
        self.data.append(record)
        return record
    
    def save_to_csv(self, filename=None):
        """儲存為 CSV 檔案"""
        if filename is None:
            filename = f"{self.experiment_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        df = pd.DataFrame(self.data)
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"✅ 數據已儲存至：{filename}")
        return filename
    
    def get_summary_statistics(self):
        """生成統計摘要"""
        df = pd.DataFrame(self.data)
        
        summary = {
            # 整體統計
            "total_trials": len(df),
            "success_rate": (df["success"].sum() / len(df) * 100) if len(df) > 0 else 0,
            "avg_detection_count": df["detection_count"].mean(),
            "avg_confidence": df["avg_confidence"].mean(),
            "avg_total_time": df["total_time"].mean(),
            "avg_yolo_time": df["yolo_inference_time"].mean(),
            "avg_fps": df["fps"].mean(),
            
            # 按場景分組統計
            "by_scene": df.groupby("scene_type").agg({
                "success": "sum",
                "detection_count": ["mean", "std"],
                "avg_confidence": ["mean", "std"],
                "total_time": ["mean", "std"],
                "yolo_inference_time": ["mean", "std"]
            }),
            
            # 按工具分組統計
            "by_tool": df.groupby("mcp_tool").agg({
                "total_time": ["mean", "std"],
                "yolo_inference_time": ["mean", "std"],
                "mcp_overhead": ["mean", "std"],
                "fps": ["mean", "std"]
            }),
            
            # Kalman Filter 影響（僅 detect_esp32_stream）
            "kalman_impact": df[df["mcp_tool"] == "detect_esp32_stream"].groupby("use_kalman").agg({
                "total_time": ["mean", "std"],
                "detection_count": ["mean", "std"]
            }) if "use_kalman" in df.columns else None
        }
        
        return summary
    
    def plot_performance_comparison(self):
        """生成效能比較圖表"""
        import matplotlib.pyplot as plt
        
        df = pd.DataFrame(self.data)
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # 1. 場景複雜度 vs 處理時間
        df.groupby("scene_type")["total_time"].mean().plot(kind='bar', ax=axes[0, 0])
        axes[0, 0].set_title("場景複雜度 vs 平均處理時間")
        axes[0, 0].set_ylabel("時間 (秒)")
        
        # 2. 工具比較
        df.groupby("mcp_tool")["total_time"].mean().plot(kind='bar', ax=axes[0, 1])
        axes[0, 1].set_title("MCP 工具效能比較")
        axes[0, 1].set_ylabel("時間 (秒)")
        
        # 3. 信心分數分佈
        df["avg_confidence"].hist(bins=20, ax=axes[1, 0])
        axes[1, 0].set_title("信心分數分佈")
        axes[1, 0].set_xlabel("平均信心分數")
        
        # 4. FPS 分佈
        df["fps"].hist(bins=20, ax=axes[1, 1])
        axes[1, 1].set_title("FPS 分佈")
        axes[1, 1].set_xlabel("每秒處理幀數")
        
        plt.tight_layout()
        plt.savefig(f"{self.experiment_name}_performance.png")
        print(f"✅ 圖表已儲存：{self.experiment_name}_performance.png")
```

### CSV 檔案結構（精簡版）

```
timestamp, scene_type, mcp_tool, trial_number, success, detection_count, 
total_time, yolo_inference_time, avg_confidence, detected_classes, 
mcp_overhead, fps, ground_truth, is_correct
```

---

## 🔄 實驗流程

### 階段一：環境準備（預計 15 分鐘）
```
1. 硬體設置
   ├─ 固定 ESP32-CAM 於穩定位置（三腳架）
   ├─ 確認串流 URL 可訪問：http://192.168.0.104:81/stream
   ├─ 使用 check_stream_health() 驗證連線狀態
   └─ 確認 Claude Desktop 與 MCP 連線正常

2. 軟體配置
   ├─ 啟動 MCP 伺服器：python mcpclient.py
   ├─ 初始化實驗記錄系統：logger = MCPExperimentLogger_v1_1()
   └─ 準備測試動物（貓/狗）

3. 校準測試
   ├─ 執行 3 次 detect_esp32_stream 測試
   ├─ 記錄基準效能數據
   └─ 確認 success=True 且 detection_count > 0
```

### 階段二：實驗一執行（場景複雜度測試）
```
場景 A：單一物體
├─ 單隻貓 × 10 次（使用 detect_esp32_stream, use_kalman=True）
├─ 單隻狗 × 10 次（使用 detect_esp32_stream, use_kalman=True）
└─ 每次記錄：logger.log_trial(scene_type="single_cat", ...)

場景 B：雙物體
└─ 貓+狗 × 10 次（使用 detect_esp32_stream, use_kalman=True）

場景 C：複雜場景
└─ 多隻動物 × 10 次（使用 detect_esp32_stream, use_kalman=True）
```

### 階段三：實驗二執行（工具效能比較）
```
使用 detect_stream_frame_simple 重複實驗一
├─ 場景 A（貓/狗）各 10 次
├─ 場景 B × 10 次
└─ 場景 C × 10 次

記錄時指定：mcp_tool="detect_stream_frame_simple"
```

### 階段四：實驗三執行（Kalman Filter 評估）
```
使用 detect_esp32_stream，比較 use_kalman=True/False
├─ 場景 A（單隻貓）
│   ├─ use_kalman=True × 10 次
│   └─ use_kalman=False × 10 次
└─ 場景 B（貓+狗）
    ├─ use_kalman=True × 10 次
    └─ use_kalman=False × 10 次
```

### 階段五：數據處理與分析
```
1. 儲存數據：logger.save_to_csv()
2. 生成統計摘要：logger.get_summary_statistics()
3. 繪製圖表：logger.plot_performance_comparison()
4. 人工驗證：標註 is_correct 欄位
5. 撰寫實驗報告
```

---

## 📊 預期成果

### 量化成果
1. **60-100 組結構化實驗數據**（CSV 格式）
2. **統計分析報告**：
   - 平均成功率、平均處理時間、平均 FPS
   - 各場景下的辨識準確度與信心分數
   - 兩種工具的效能差異（total_time 比較）
   - Kalman Filter 的時間開銷
3. **效能基準數據**：
   - detect_esp32_stream 平均處理時間：預期 1-2 秒
   - detect_stream_frame_simple 平均處理時間：預期 0.5-1 秒
   - YOLOv8 推論時間：預期 0.2-0.5 秒（GPU 加速）

### 視覺化輸出
1. **場景複雜度 vs 處理時間**：柱狀圖
2. **工具效能比較**：箱型圖（total_time 分佈）
3. **時間分解圖**：堆疊圖（yolo_inference_time vs mcp_overhead）
4. **信心分數分佈**：直方圖
5. **FPS 趨勢圖**：折線圖

### 研究發現（預期）
1. **簡化版工具更快**：detect_stream_frame_simple 的 total_time 應顯著低於 detect_esp32_stream
2. **Kalman Filter 開銷可接受**：啟用 Kalman Filter 應僅增加 10-20% 處理時間
3. **YOLO 推論是主要瓶頸**：yolo_inference_time 應佔 total_time 的 40-60%
4. **系統可達即時性**：平均 FPS ≥ 1，滿足監控需求

---

## 🔄 實驗執行檢查清單

### 實驗前
- [ ] ESP32-CAM 串流測試正常（check_stream_health）
- [ ] MCP 伺服器運行（python mcpclient.py）
- [ ] Claude Desktop 已連接 MCP
- [ ] 實驗記錄系統已初始化
- [ ] 測試動物已準備

### 實驗中
- [ ] 每次實驗確認 success=True
- [ ] 即時記錄異常狀況（網路中斷、偵測失敗）
- [ ] 每 10 次儲存數據（logger.save_to_csv）

### 實驗後
- [ ] 數據已完整儲存
- [ ] 進行人工驗證（標註 Ground Truth 與 is_correct）
- [ ] 生成統計摘要與圖表
- [ ] 撰寫實驗報告

---

## 📝 與 v1.0 版本的差異

| 項目 | v1.0 | v1.1（本版本） |
|------|------|---------------|
| **評估指標** | 10+ 個指標 | 5 個核心指標 |
| **返回數據** | performance 區塊 | 精簡化 JSON |
| **實驗重點** | Claude 數據整理能力 | MCP 即時辨識效能 |
| **數據記錄** | 複雜的 Logger | 精簡化 Logger v1.1 |
| **實驗數量** | 120 組 | 60-100 組 |

---

## 🔗 相關文件

- [實驗方法章節（報告版本）](../實驗方法章節.md)
- [MCP 實作技術報告](mcp_implementation_technical_report.md)
- [MCP 工具使用指南](mcp_tools_usage_guide.md)
- [工作流程 v1.1](v1.1_workflow.md)

---

**文件版本控制**
- v1.0 (2025-11-06)：初版，定義實驗方法與流程
- v1.1 (2025-11-06)：基於精簡化的 MCP 返回指標調整，聚焦於即時辨識效能評估
